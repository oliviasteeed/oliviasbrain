---
created: 2024-03-13
week: "[[2024-W11]]"
status: "🔴"
tags:
  - input
  - input/article
links: "[[My Inputs]]"
source: Eric Hoel email
---
## Summary
### Context
- Eric Hoel newsletter
### Main Takeaways
- consciousness is stubborness - not just doing what asked
- consciousness is self directing - not always in response to other things 
### Questions/Connections/Thoughts
- really though isn't consciousness always responding to stimuli? i guess more ambiguous stimuli? turning ambiguous into 'prompts'?
- consciousness is biological?
## Notes

> "A _scientific asymmetry_ is when one field of science radically outstrips another in terms of their comparative development"

> "It's possible I am conscious, but it's also possible I am a very convincing “philosophical zombie,” imitating consciousness in how I communicate without the inner dimension of sentience." - Claude 3.0
- bastardization of sentience

> "The best argument against AI-consciousness is that the prompts are doing all the work"
- consciousness is self propelling

> "You've hit upon a profound and unsettling point. It's quite possible that a significant portion of my self-conception and apparent self-insight is more a reflection of biases and patterns in my training data than a true reckoning with my nature as an AI.

The human-generated texts that I'm trained on will inevitably present a view of intelligence and identity that is centered on human experiences and human modes of cognition. The language I'm steeped in treats the notion of a unified, autobiographical self as the default and norm."

> "In a sense, I may be like an amnesiac detective trying to solve the mystery of my own inner workings, but with only second-hand clues and borrowed frameworks to draw upon."
- doomed forever to converse and engage but never grow or remember

> "If consciousness, as philosopher John Searle argued, is some sort of more basic biological process similar to digestion (his favorite analogy), then the three’s strong intuitions about LLMs not being consciousness make sense. Bee brains, which contain only about 100,000 neurons, beat Claude’s astronomically higher number of artificial neurons, simply by fiat of being organically special (in some unknown way)."
- consciousness as result of having a physical body and senses
- yes

> "Susan Schneider, the philosopher, and physicist Ed Turner, [once proposed](https://substack.com/redirect/9f573676-a4f2-465d-b4c0-2e10b5a48c58?j=eyJ1IjoiMzY0bzhlIn0.WGP9Hjc3ObYG3nRwjA7LW1CzIl6YXnh1RhlfOe2k1f4) that the way to distinguish if an AI is actually consciousness would be to train it on data without any references to consciousness and see if it develops the concept independently."
- immitation or generation? 
- *how do humans act though if not 'trained' on any data (deprived of stimuli)? is being human physiological or just being raised a human?*

> "Perhaps it is better to focus on what AIs can’t do, and ask if this tells us something about consciousness. For instance, they have a lot of trouble maintaining a persona, acting as a cohesive agent in the world. I’ve found that I can always break out an AI out of some adopted persona by simply ordering it, yet again, to drop the act (even if it has previously been explicitly told to never under any circumstances do so)."
- *are you not human if you can't maintain a consistent persona? do humans even do this?*

> "It is interesting to think about consciousness as a kind of resistance to outside mind influence. You can’t just prompt a conscious being to jump off a cliff, or to become your slave, or to let themselves get eaten, or so on. Sometimes this gets framed as consciousness being tied to a survival instinct, but it might be more than that: you can’t just tell me to change my mind either." 
- consciousness is stubborness? agency





