---
created: 2023-12-31
status: ğŸ”´
tags:
  - input
  - siat
links: "[[My Inputs]]"
professor: Wolfgang Stuerzlinger
semester: Spring 2023
---
## Summary
### Context
- 
### Main Takeaways
- 
### Questions/Connections/Thoughts
- 
## Notes

Week 1:

  
Chapter 7: Design Methods:

1. Design Brief: target solution including features, personality, audience and affordances plus hypothesis to realize it
    

- consider focus, audience, features, feeling and constraints
    

2. Design Principles: statements clarifying personality of project to act as guiding light during process
    

- make list of principles focusing on unique aspects and affordances, refine and combine adding visuals and explanations, share and iterateÂ 
    

3. Sketching: fast form exploration for personal and group explanation
    

- start with most interesting/key moments and build out, make 6 options before continuing to iterate digitally, use colour/annotate to add clarity
    

4. Sketchboards: assembling sketches to view overall system
    

- lay out basic structure of experience and fill in with sketches and annotations, review and iterate with othersÂ 
    

5. Task Flows: considering sequence of user experiences to create a smooth experience and avoid breakdown at transition points
    

Top Down: chronological sequence

Bottom Up: start with important or interesting and build out

- consider alternative entries, exits and abandonment
    

6. Wireframes: skeletal (black and white) depiction of product look, information included and overall layout to create sense of information/element relationships
    

- list required screens in flow, then create wireframes considering sequence, information density/emphasis, grid/order, error messages and feedback and alignment with design principles
    

  

About Face Chapter 1: Design Process for Digital Products:

Design: imposing order with intentionÂ 

Human-Oriented Design: integrating user needs/goals/context with business/technical constraints and opportunities to create useful, usable, desirable, feasible, viable products

  

Steps to Success:

1. priority on user goals:
    

- both business and personal goals (what and why) need to be addressed
    

What? operation > action > task > activity (changes quickly)

Why? motivation/goals/expectation/aspiration/meaning (changes slowly)

2. study users to understand goals/needs:
    

- understanding of goals and context equally important
    
- good design makes users more effective
    

3. separate designers and developers
    
4. use a systematic design process
    

  

Implementation Model: how task is actually completed

Represented Model: what designers show to facilitate creation of helpful mental model

Mental Model: how users think task is completed

  

Design Principles:

1. User interface should be based on mental model not implementation model
    
2. Goal directed interactions reflect user mental models
    
3. User interface design is not guesswork
    

  

Goal-Directed Design:

1. Research: gathering data about current/prospective users, stakeholders, experts
    
2. Modeling: synthesizing data into domain models (information flow diagrams) and user personas (archetypes)
    
3. Requirements Definition: consider needs/motivations/skills of personas through context scenarios
    
4. Framework Definition: overall concept of behaviour, form, visual design (using service maps, blueprints for services or inputs and form factor for physical devices)
    
5. Refinement: solidify details by walking through experience to ensure cohesion
    
6. Developer Support: collaborate with development team to resolve unanticipated issues that arise in production
    

  

Question: You are leading a team of developers, graphic and visual designers and interaction designers in the creation of a new file-sharing app for university students. What methods would you use to define the project, and ensure collaboration between the different members? How could you ensure a cohesive product despite the varied expertise and focus of each member?

  

Answer: Creating a design brief and design principles would be a helpful way to define the project. These could be shared with the team for feedback to ensure everyone is in agreement, and many points of view on the task have been considered. Having these would also allow everyone to remain on the same page, and understand the goals of the project, and the plan to get there. To encourage collaboration, creating a sketchboard of the general structure illustrated through sketches, and inviting team members to comment, question and add would be productive. This would give all members and accessible way to understand the goal, and form the end result with their unique lens of expertise.

  

Lecture Week 1: UI Thinking

  

User Interface: method of communication with system (does not have to be computer)

- not one-size-fits all, â€œgoodâ€ depends on context
    

Roles of UI Designers: define whatâ€™s included in interface, onboarding experience, understanding users

UX: big picture, what user needs and why they would use it

UI: details of how users interact with product, visual layouts, flows, responses to input

- intersection of many disciplines makes successful product
    
- function is beauty, behaviour as important (or more) as aesthetics
    

  

Week 2:

  

Just Enough Research, Erika Hall

  

Chapter 7: Evaluative Research: assessing design merit

1. Heuristic Analysis: easy/quick/cheap testing based on experience, qualitative
    

1. system status visibility
    
2. system/real-world match
    
3. user control/freedom
    
4. consistency/standards
    
5. error prevention
    
6. recognition instead of recall
    
7. flexibility/efficiency of use
    
8. aesthetic/minimalist design
    
9. help users recognize/recover from errors
    
10. help/documentation
    

3. Usability Testing: bare minimum test
    

1. learnability (1st time use)
    
2. efficiency (once learned)
    
3. memorability (do users remain proficient?)
    
4. errors (amount/severity/recovery)
    
5. satisfaction (pleasant to use?)
    

How To:

- 4-8 target users per persona to complete specified tasks using prototype
    
- facilitate (instruct) and observe (take notes/record)
    

Scale Findings (Problems) By:

1. Severity:
    

1. High: prevents from completing task
    
2. Moderate: can complete task with some issues
    
3. Low: does not impair task completion
    

3. Frequency
    

1. High: more than 30%
    
2. Moderate: 11-29%
    
3. Low: Less than 10%
    

Sort Problems:

1. Tier 1: high impact problems (must be resolved)
    
2. Tier 2: moderate/low or low/moderate (should be resolved)
    
3. Tier 3: low impact (could be resolved)
    

  

Chapter 8: Analysis/Models

1. Affinity Diagrams: first pass
    

1. put interesting parts of user research on sticky notes (especially user goals)
    
2. group by pattern
    
3. make actionable design principles/mandates based on patterns
    

3. User Personas: fictional user archetypes matching target users/ur interviewees (from data when possible)
    

1. name + photo + demographic
    
2. role
    
3. quote (from user research)
    
4. goals (generally and product-specific)
    
5. behaviours/habitsÂ 
    
6. skills/capabilities (technical, physical, cognitive)
    
7. environment
    
8. relationships (impacting product use)
    
9. scenarios (stories of product interactions based on research)
    

5. Mental Models: internal representations based on social/experiential knowledge
    

- intuitive = matches mental model
    

1. user research
    
2. affinity diagram using actions/beliefs/feelings as categories
    
3. group stickies around tasks/goals they relate to
    

Conceptual Modeling: map mental model to information architecture

Gap Analysis: use mental models to identify gaps between needs and

offerings

4. Task Analysis/Workflow: breaking task down into steps
    

1. based on contextual inquiry and user research
    
2. both cognitive and physical components
    
3. each step + initial state/prompt to start action + steps with interruption/resumed action
    
4. make flow diagram
    

  

Question: Your friend is a talented software engineer who is excited to show you the new messaging app he claims is ready for release. As a UX designer, you are interested to test the app, and find that you are unable to make a new chat, or delete previous chats. When asked about testing, your friend claims it makes sense to him, so should be intuitive. At this point, the app is mostly done, and a remake is not possible, but user testing could still benefit the project. What would you recommend your friend do to improve his app considering the late stage of development and short timeframe?

  

Answer: Considering the friend did no testing, he likely does not have target users in mind to use the app, so user testing may be difficult. Basic heuristic testing, where they provide the app to friends and family to try could help identify high severity problems that must be resolved to ensure the app is successful, or at least usable. Working with the friend to develop some basic user personas, and finding suitable test candidates would take more time, but would be beneficial in finding high and moderate severity problems, and providing gap analysis to understand the gaps between the users needs and app offerings. This would include finding samples of users that fit each persona, and giving them a list of tasks to complete while observing and recording behaviour.Â 

  

Lecture Week 2: UI Design Guidelines

- these apply to all interfaces and systems regardless of digital or physical
    

  

1. Visibility of System Status: keep user informed about what is going on with feedback within appropriate timeframe
    
2. Match Between System and Real World: use words/phrases/concepts familiar to users, real-world conventions, natural and logical ordering, matching user mental models
    

Principle of Anticipation: anticipate needs of user, do not expect to leave page and search for information, tailor to location/context to make it easily understandable

3. User Control and Freedom: users need emergency exit/undo to leave unwanted states quickly, donâ€™t force arbitrary linear path, allow users to enter at many points
    
4. Error Recognition: informative and helpful error messages that indicate problem and suggest solution, redundancy in help methods, keep security in mind as well
    
5. Error Prevention: better than good error messages is no errors in the first place, using helpful constraints and suggestions, good defaults, forgiving formatting (talk to users and figure out how they actually use product), tell rules before expecting input
    
6. Recognition > Recall: STM limitations mean we can recognize a lot easier than recall, make objects, actions, options visible to user, images instead of text, memorable icons and states
    
7. Flexibility and Efficiency of Use: different functionalities for beginner/novice and experienced/experts that do not interfere with each other (shortcuts)
    

Accelerator: shortcut that makes expert workflow more efficient without impeding beginners

8. Help and Documentation: best case do not need this, but if necessary make understandable and actually helpful
    

1. Reactive: answering questions and troubleshooting problems
    
2. Proactive: familiarize with interface/functionalities before experience issues (onboarding)
    

1. Push Revelation: out of context tip (popup, splash screen)
    
2. Pull Revelation: contextual tips (hover to view description)
    

9. Consistency and Standards: consistency means no wondering what words and actions mean, visual language
    

1. Internal: within app and company
    
2. External: industry conventions/similar products
    

11. Aesthetic and Minimalist Design: no irrelevant information to distract from important, draw attention to actual content
    

  

Week 3:

  

Understanding Context (Andrew Hinton): Chapter 13: Digital Interaction

Interface: artificial environment bridging gap between digital software abstraction and physical affordance/semantic understanding

- can be between two systems of any kind
    
- humans are ambiguous, complicated systems
    

Last 50 years: boom in interfaces due to increased digital tools

- software initially made only for trained experts
    
- now expected to be accessible to general public in surrounding context
    

  

Semantic Function of Simulated Objects:

- used to be that object = object
    
- we also treat representations (images) as objects
    
- interfaces have semantic function to simulate physical affordances
    

Interactive: associated with rise in digital technology, capability of systems to dynamically respond to input

1. Skeuomorphic Design: literal translation of physical controls on simulated digital tool (assists to bridge gap of understanding)
    
2. Flat Design: eliminating simulated physical signifiers (once conventions are learned)
    

- context of control and simulated interaction also depends on language used
    
- interaction with software is not direct, through abstraction, system image likely does not match actual processes taking place (email)
    

Extended Cognition: organization of objects to afford further action

  

Modes and Meaning:

Mode: condition that changes results of action (that would be same under different condition)

1. Sticky: remain persistent after engaged (caps lock)
    
2. Non-Sticky: only engaged when currently activated (shift)
    

- change context and rules of cause and effect which is unnatural and our perceptual systems are equipped to deal with them (guarantee mistakes)
    
- increasing complexity/demand for more functions with same space leads to more modes
    
- can be fine when users are aware and motivated to learn, but when unaware or using muscle memory (in wrong mode) can be dangerous
    
- cause controls to be nested within many layers of interface (hidden, inaccessible)
    

  

Summary

This weekâ€™s reading covered the roots of interface design, and the challenges that arise when translating and conveying functionality to users. Initially, software was made for trained specialists only, so did not have to be immediately understandable, as all users would be subject-matter experts and receive adequate training. Now that digital devices have proliferated our lives, there is an expectation that softwares are usable by all and in any context. This is an irrational desire, as no interface is actually â€˜natural,â€™ they all depend on simulating physical properties to indicate functionality and learned conventions (from physical and other digital artifacts) to imply function. Similar to how we learn to read, we learn to use interfaces based on trial and error and socialization. Initial digital interfaces relied on skeuomorphism, a literal translation of physical objects, to be understandable, because users did not have learned conventions of how digital devices should work. Now that devices are pervasive and many have learned through skeuomorphism, flat design seems intuitive and understandable to many. However, if the first generation of iPhone users had flat design, they likely would have struggled to use the device because they lacked the semantic conventions of usage most have achieved now. Devices now also use numerous modes to extend functionality while keeping the same number of controls, which leads to nesting and hiding functions within levels of interface, and more errors.

  

Question:

You are an interface designer tasked with creating a book-lending application for public libraries. The app will be used by an estimated age range of 5 to 75 years. How can you ensure the most possible users can understand and effectively use the app considering the differing semantic and functional conventions the diverse users will hold?

  

Answer:

Users on the older range of the spectrum will likely be familiar with physical libraries, and the process of viewing books on shelves, selecting one and checking out. Younger users may not have ever been to a library, so emulating this experience will not be natural to them. Because there is such a wide variety of users, with such varied understandings, it may be useful to create different â€˜versionsâ€™ or layouts of the app prioritizing different information. For older users, using static skeuomorphic signifiers of books and shelves may help bridge the gap, relying on their physical understandings to afford effective use. Younger users may be more comfortable using digital technology and social media apps may find swiping through quick previews, videos or animations for each title more stimulating and understandable. Perhaps users in the middle would prefer a conventional website-style experience where one clicks on a certain title and is brought to a secondary page providing secondary information. Allowing all these modes to be toggled easily and accessible would allow users to choose what view works best for them, and hopefully increase the usability and understanding of the app for each.

  

Lecture Week 3: Affordances and Heuristic Evaluation

Aesthetic Affordances (Signifiers): interface to encourage cognitive function of user to use complex tool easily

- clearly cue users of expectations
    
- match visual language to functionality/expectations/mental model
    
- not natural or intuitive, all interface usage must be learned
    

  

Users and System Behaviour: be aware of user expectations and system function (do not map directly, should be abstracted to be better understood)

- good default is the common case
    

Skeuomorphism: physical, conceptual, visual representations mimicking physical interface for easier understanding of interface

- what works changes over time, symbols/meanings change, can become increasingly abstract (consider understandings of different user groups)
    

  

Heuristic Evaluation: evaluating interface based on checklist of high-level design guidelines, works with any fidelity (sketches to prototypes)

- cheapest, fastest, easiest way to catch most usability errors early in process
    
- â€œworksâ€ isnâ€™t enough, it has to solve user problems well
    
- not a substitute for usability study
    

How To:

1. 3-5 evaluators (catch 66-5% of usability errors), usability experts, end users and dual experts (usability and subject matter)
    
2. individuals explore interface considering Neilsen guidelines for an hour
    
3. assess severity of issues by
    

1. Frequency (how much of user base will experience error?)
    
2. Impact (easy or difficult for user to overcome?)
    
3. Persistence (one time or repeatedly?)
    

5. compare notes
    

Pros:

- tells big problems, helps improve usability
    
- minimalist approach
    
- end users not required (but use them if you can)
    
- cheap and fast
    
- validates design decisions
    

Cons:

- high level principles, not simple checklist
    
- do not capture subtleties/all problems
    

  

- most effective in early stages to refine concepts before building
    

  

Evaluating Heuristic Evaluations:

(start with tasks, then allow open-ended exploration to check both)

1. Self-Guided: open-ended exploration, good for checking diverse aspects/pitfalls
    
2. Scenario-Based: completing specific task, ensures relevant UI portions are well evaluated
    

Outcomes: issue and guidelines violated and severity with optional recommendations from evaluator

Prioritize: severe issues, frequent issues, easy fixes

  

Overall Process:

1. interview end users/explore competition/research
    
2. synthesize a concept
    
3. heuristic evaluation of sketches and lo-fi prototypes
    
4. make the product lo/med-fi
    
5. usability testing to ensure it actually works
    

  

Week 4:

  

Lecture Week 4: Thinking Like Users

â€œknow thy userâ€

1. User Goals: prioritize design decisions to further system context/goals, user goals are the design target
    

â€œthere is no avoiding the hard work of really understanding the people who will actually interact with your productâ€

- often products bought based on marketing/price or by managers who will not be using them with no concern for usability
    

1. End Goals (what): task they are trying to accomplish
    

- made up of series of tasks to reach result
    
- quickly changing based on situation and technology
    

2. Experience Goals (how): type of experience user wants while accomplishing end goal
    

- very subjective
    

3. Life Goals (why): greater goal user is trying to accomplish with end goals
    

- made up of series of tasks to reach a result
    
- underlying motivations, slow changingÂ 
    

2. User Types:
    

1. Beginner: where nobody wants to be
    

- motivated to learn, looking for fast mental model match
    
- not dumb just ignorant, donâ€™t know how much they donâ€™t know
    
- need onboarding or level of expertise needed down
    

2. Intermediate: where most people are
    

- may need functional reminders/documentation
    
- will seek assistance
    
- may begin to customize interface and workflow
    
- largest group, users pushed here from both sides (the design target)
    

3. Expert: very few people
    

- frequent users
    
- push boundaries of system capabilities
    
- most vocal, give the most feedback (may be most aware of what system needs but be careful to not only design for experts)
    
- tired of repetitive tasks
    
- customize workflow/interface
    
- retirement, updates, promotion lose experts
    

3. Onboarding:
    

- avoid taking users out of first moments of onboarding at all costs (delay email sending)
    
- beware what repeated buttons/messaging will mean to users
    
- permissions asked paired with direct action (so they know why)
    
- should not be too long/ information should be in chunks
    
- Â â€œa PDF is not an onboarding experienceâ€
    
- donâ€™t block access of elements by highlighting/mix up intermediate and beginner users
    
- donâ€™t make people read too much on phone
    
- if you want to make people learn donâ€™t make them do multiple tasks in parallel
    

4. Users are Humans:
    

- users may not know what they want, may not know what other options they have
    
- best to interview and observe to gain insight into user needs
    

5. Personas: archetypes not stereotypes of end users
    

â€œAs a (persona) I want to (goal) so I will (task)â€

- to help whole team empathize and consider user needs
    
- built from user research (talking to users!)
    

Include:

1. name, occupation, context
    
2. goals
    
3. influences
    
4. experience (with product/similar technologies)
    
5. motivations/frustrations
    
6. where/when they use the app
    

Pitfalls:

- everyone fills in gaps differently, persona is subjective
    
- â€œwe do not see things as they are, we see them as we areâ€
    
- good starting point, not exact person
    

Alternatives: use job stories as opposed to personas to avoid making

assumptions

â€œWhen I am in (situation) I want to (motivation) so I can (expected

outcome)â€

1. Jobs to Be Done: focus on customer motivations/what job is product hired to do
    
2. Job Stories: focus on tasks and goals (more realistic about action)
    

6. Using User Goals: keep focus on design-related information
    

1. what are they doing? (usually end goals)
    
2. what are they thinking? (usually about task/given goal)
    
3. what are they feeling? (usually driven by experience goals) (very subjective)
    

Goal: something person wants to achieve

- constant over time
    
- system independent
    
- changes state of their world
    

Task: performed to reach goals

- change over time/with technology
    
- system dependent
    
- require problem solving
    

Questions:

1. why would they use system (what goal does it serve)?
    
2. what do they need to reach goals (what tasks)?
    
3. what are common problems?
    
4. where and when are they using system?
    

  

Animation for Attention and Comprehension:

Objectives:

1. draw attention
    
2. add funÂ 
    
3. appear modern
    

Considerations:

1. goal (attention, continuous transition, indicate relationship)
    
2. frequency (once or repeated)
    
3. mechanics (caused directly or indirectly)
    

Directly: must be triggered within 0.1s of user action to establish cause and effect

User Attention:

- peripheral motion distracts users (bottom-up processing), competing with goal-oriented top down-processing
    
- speed of attention shift depends on perceived animacy (speed and autonomy)
    
- if already in fovea, animation does not trigger same visual response
    

Takeaway:

1. fast for attracting attention to something user must attend to/act on
    
2. slow for indirect/not user-initiated
    

  

UI Animation: Eye Pleasing Problem Solving:

- users like motion because it creates perception of real-life interaction
    
- must be functional element as well
    

Problems Solved by UI Animation:

1. action feedback (done)
    
2. progress feedback (how much done/how much longer)
    
3. simplifying how much onscreen at once
    
4. supporting hierarchy of key elements first
    
5. making interactions feel natural/smooth
    
6. adding visual interest
    

  

Interviewing Users:

1. General Curiosity
    

1. brain dump to get out assumptions
    
2. clear objective but willing to explore
    
3. interview in natural setting
    
4. ask what you think you already know (they are expert you are novice)
    
5. no distractions
    

3. Build Rapport
    

1. adhere to social expectations
    
2. only talk about yourself to make them comfortable
    
3. work towards stories (over answers)
    
4. frame around learning
    
5. listen with words (follow up questions) and body
    

Conducting Interviews:

1. Establish Objectives:
    

- interview stakeholders to understand goals
    

2. Find Participants
    

- define users at several parts of transaction, make screening form
    

3. Plan Interview
    

- introduction and participant background
    
- main body (most questions)
    
- projection/dream questions (more speculative)
    
- wrap up (ask for any other input/things missed)
    

4. Schedule Interview
    
5. Thanks Incentive
    

  

Summary:

This weekâ€™s readings centered around guidelines for implementing UI animations and for interviewing users. Although UI animations are an easy way to add visual interest and making interactions feel natural and exciting, they can be overused to the detriment of the userâ€™s experience. When animations appearing in the userâ€™s periphery are fast and self-propelled, they cause a bottom-up perceptual stimulus response, distracting the user from their actual task. This means that animations residing in the userâ€™s periphery should be slow, so as to not distract them, or nonexistent. Even for animations in the userâ€™s fovea, it is important to ensure there is an intent and function being achieved to avoid unnecessary and annoying interactions. The frequency and duration of animations also impacts the userâ€™s impressions of them, so itâ€™s best to not overuse them to avoid wasting the userâ€™s time. Good applications of UI animations are for showing feedback to user interactions and help them understand the cause and effect responses of their actions (if the microinteraction response is within 0.1 seconds of the userâ€™s action). Animation can also be used to emphasize hierarchy and limit the number of elements on the screen at once, creating a cleaner UI. Interviewing users is a key aspect of UX design, and involves careful preparation to ensure it adds value. Understanding objectives is critical to asking the right questions and selecting the right users. Once this is established, one can start screening potential participants and conducting interviews. Getting good insights from interviews depends on how comfortable one can make the participant, so their responses become more like stories than direct answers. Keeping open body language and asking follow-ups promotes this. Use a basic plan of questions to structure interviews but allow it to flow naturally as well as the most useful insights may be off-script.

  

Question:

You are making a vocabulary learning app targeted at children ages 3 to 12. The app allows children to explore different words based on graphics in interactive scenes that become more abstract as they progress through levels. It also allows parents to input words and influence the scenes with themes and words they think are relevant for their child to learn. How would you best employ UI animations to increase the functionality and enjoyment of the app across the diverse user-base?

  

Answer:

UI animations can be fun and engaging for children, so they definitely have a home in this app. When children are focused on learning specific words after tapping on elements in the scene, it would be best to keep the background animations slow and predictable to avoid drawing their attention away and making focusing (and learning) difficult. On the other hand, in the center of the screen where they would see educational content it could be useful to include more dynamic animations that may be interactive to keep user focus, as animations in the center-of-vision do not interfere with focus as much. While the child is interacting with the scene at large, there could be many interaction-based animations, as they arenâ€™t focused on any one aspect in particular, so each element could try to catch the childâ€™s attention (to encourage them to tap and learn about it). As the scenes progressed from basic to more complex words, it may be beneficial to decrease the animations, or make them fewer but more complex, as older children may find them annoying or childish instead of engaging. As with the parent-geared side of the app, animations should be kept to a minimum and only employed to indicate feedback and serve functional purposes, as otherwise they would become distracting, annoying and tedious.

  

Week 5:

  

Design for Real Life

  

Chapter 6: Learn from Users:

- best way to make users â€œloveâ€ product is to â€œloveâ€ users
    

Meet Users:

1. questions to gather context/details
    
2. questions to probe/clarify/uncover motivations
    
3. questions to contrast approaches (to learn mental models)
    

Find Fractures: coax interview towards tipping point

1. can you think of a time when?
    
2. how did you make that decision?
    
3. what does that mean to you?
    
4. what would you like to see happen?
    
5. tell me more about that?
    

Go to Them: contextual inquiry gives more insight into unique user contexts

Broaden your Vision: seek to understand/design for edge cases (low literacy/income)

Explore Touchy Subjects:

1. collaging to explain emotions/situations (images with captions)
    
2. â€œwe can stop at any timeâ€ not forcing people past breaking point
    

Valuing Openness: get beyond comfort zone and expand perspective

  

Chapter 7: Humanize Your Process:

Create Realistic Artifacts:

1. Imperfect Personas: realistic details/hardships/photos from user research
    
2. User Journey Maps: helps to understand diverse contexts of use
    

1. Lens: persona/scenario mapped
    
2. Touchpoints: moments user interacts with organization
    
3. Channels: how user interacts with organization (online, phone, in-person)
    
4. Actions: what is done at each point to meet their needs
    
5. Thoughts: how people frame experiences and define expectations
    
6. Feelings: emotions people have along the journey (highs and lows)
    

Document Issues:

7. Pain Points: places users get stuck, need help or leave
    
8. Broken Flows: places where touchpoint transition isnâ€™t working properly
    
9. Context Gaps: places where user needs a specific thing that isnâ€™t there
    

Outcomes:

- prioritizing for urgent use cases
    
- finding places where user/functions are out of synch
    
- finding context gaps for stresscase users
    

Strengthen Your Process:

1. WWAHD Test: real copy out loud/imagine explaining to a stranger
    
2. Premortem: imagine product failed and ask why
    
3. Question Protocol: make sure all user information is intentional and appropriate
    

1. who users the answer?Â 
    
2. what do they use it for?
    
3. is answer required or optional?
    
4. if required what happens with bogus entry?
    

5. Designated Dissenter: someone to assess decisions and challenge assumptions (to avoid groupthink), take turns
    

Stress-Test Your Work:

1. More Realistic Tests: so other cognitive task first to emulate real life conditions
    
2. Stress Roleplays: using fantasy scenarios to get user out of their head/cultural norms
    

Cross-Discipline Collaboration: gets you more contexts/challenges more assumptions

  

Summary:

This weekâ€™s readings were about getting the most out of user interviews by going beyond small talk and surface-level observations, and applying that research to the design process. To best understand users, it is important to interview them in the context they will be using the product. This allows you to gain a broad understanding of the different use cases, and the conditions people will be working in, which will help in deciding what information to prioritize. It also makes interviewees more comfortable, and can lead to them opening up and sharing stories as opposed to simple answers. Stories contain more depth and detail, so will help more in understanding their emotions and struggles with specific products and situations. These understandings can then be applied to creating realistic personas based on the user research, that include flaws, struggles and complexity. These personas facilitate empathizing with the intended user, and will encourage more care to be placed in creating a smooth experience. The realistic persona can also be applied to a user journey map, which maps out a userâ€™s experience of a specific context and activity, which helps understand all the integrated interactions the task contains. Using urgent and emergency scenarios, and â€œedge caseâ€ users in user journey maps is most beneficial, as it will best emulate the real moments people struggle with systems, and help guide prioritization of content and content design to be understandable to all.

  

Question:Â 

You are hired to make a banking website where users can access their accounts and manage transfers easily. You have a list of tasks from the client they would like to be possible and a description of the average user of the site. What is the issue with proceeding to design and implement it with only this knowledge, and how could you expand your understanding to result in a product with better user experience?

  

Answer:Â 

The issue is that the only information given is very abstract, and not tied to any specific user or goal. It is easy to imagine how a site will work in the best case scenario when all is well, but this ignores issues people will have when they are stressed, rushed or lack comprehension skills. Interviewing potential users would be a good first step to understand more than an imagined â€œaverageâ€ user, and get some examples of more diverse user needs and contexts. It is a good idea to design for users of lower literacy and financial status to maximize usability for all users, and user interviews could help to illustrate these concepts. After conducting user interviews, this knowledge could be applied to personas and user journey maps to understand specific use contexts and goals instead of abstract and isolated tasks. This would ensure consistency and flow across touchpoints, avoiding context gaps and broken flows. Lastly, involving members of the client organization, or people in other disciplines working on the same project could help to expand the horizons of what is considered necessary and important in the final product, and the range of tasks and user motivations to account for.

  

Lecture Week 5: Talking to Users

  

User Interviews:Â 

1. Why? only good user research if generate valid user data
    
2. When? before creating design, to enrich contextual understanding, at end of usability test
    

Cons:

- human memory is fallible (cannot remember details or make up events to rationalize)
    
- users are pragmatic and concrete (no idea about usage)
    
- only the present generates valid data, past can be misremembered, future is speculation (use rapid prototyping)
    
- won't answer specific interface/information architecture questions (infer from answers)
    

Pros:

- exploring general attitudes of users, how they think about problem
    
- exploring problem space
    

Method:

- set a goal (specific), ask what stakeholders want and designers need to know
    
- make them comfortable (more likely to talk and let guard down)
    
- short intro chat, explain reason, make them feel heard, do not rush, start with easy questions, let users finish thoughts, show empathy (authentic)
    
- prepare list of questions (clear, not leading, used as baseline for â€œsemi-structuredâ€ interview)
    
- prepare for interviewees hitting a dead end/not having a response (help them find the answer)
    
- response anticipation strategy (prepared follow ups/segues/prompts)
    
- prepare more questions than you need to accommodate talkative and quiet users
    

Questions to Aim For:

- aim for dialogue provoking questions
    
- ask about one thing in each, specific events
    
- give them opportunity to think about answers
    
- elicit rich, unbiased answers from interviewee
    

Questions to Avoid:

- Leading: prime user by inadvertently suggesting a response
    
- Closed: eliciting yes/no answers
    

Tools:

1. Flow: things to do to keep them talking
    

1. Addition: â€œi see, yesâ€
    
2. Encouragement: â€œI understand, thatâ€™s interestingâ€
    
3. Body Movement: non, lean forward, eye contact
    
4. Attentive Silence: wait for person to finish talking, give their answers space
    

3. Non-direction: continuing conversation in organic direction
    

1. Reflecting echo: repeat last few words (~3)
    
2. Question-to-question: give a neutral question (â€œwell what is your feeling on this?â€)
    
3. Attentive Listening: form a question to test your understanding of what they just said (repeat it back to them)
    

5. Transition: closing previous conversation and opening a new discussion
    

1. Reversion: associate ideas from previous point to new point (â€œit sounds like you use email a lot, do you use IM similarly?â€)
    
2. Mutation: unstructured question raising without direct connection to previous conversation (abrupt) (â€œweâ€™re going to move on and talk about xâ€)
    

7. Specificity: getting more specific information
    

1. Situation Re-Presentation: talk about something then have user do action/interact with it (present the stimulus) (â€œweâ€™ve talked about how you use email, now letâ€™s watch you check your emailâ€)
    
2. Reconstruction: recall specific reaction at some event (â€œtell me about last time you checked your emailâ€)
    

9. Depth: getting detailed feelings about something
    

1. Emotion/feeling: question using feeling term (â€œdid this make you feel frightened?â€)
    
2. Projection: question about hypothetical friend if it seems sensitive to them (â€œhow do you think your friend felt?â€)
    
3. Attentive Listening: form a question based on what they just said to confirm you understand their emotions around it
    

11. Individual Context: making interview about specific interviewee
    

1. Personal Self-Description: direct request for description of self (â€œi am interested in what your think not what you think others feelâ€)
    
2. Parallel: ask about parallel situation where reaction would be similar or related
    

Interview Distortion:

1. Internal: problems internal to interviewer (personal traits, lack of experience, listening skills)
    

Reduce By:

- restating what people say
    
- taking notes
    
- corroborating with other sources (multiple interviews/interviewers)
    

2. External: problems with interaction between interviewer and interviewee (distractions (finger tapping), conflicting messages (body language), violation of social norms, emotional discomfort)
    

Reduce By:

- analyzing own behaviour
    
- being aware of social norms
    
- arranging appropriate environment
    

Location: can be in userâ€™s site, controlled lab environment, remotely, using online meeting tools

Consider:

- user convenience and comfort
    
- team convenience (do you want/need team to observe interviews?)
    
- context and examples (is it important that users have their own tools?)
    
- bias (consider locational impact of user stories (work v. home))
    

  

Critical Incident Technique (CIT):

- ask users to recall specific instances of difficulty or success, often more vivid and provide useful details
    

Pros:

- quick, captures incidents over long timeframe and rare and uncommon incidents
    
- emphasis on more important issues
    
- flexible
    

Cons:

- relies on memory and pure recall
    
- does not represent typical usage
    

Query Effect: can make up an opinion about anything, will do so if asked

  

Talking to User Without a Study: analyzing requirements of problem space

- do not ask them what they want, makes it harder to interview, yields wrong insights
    
- get background information about what user is trying to do, critical to understanding users
    
- asking why to get to root of motivations
    
- ask how they currently do tasks, experience pain points and strategies/workflows
    
- ask what their current plan is (what areas need most help, validates or disproves hypothesis for building something)
    

  

Ethics:

Human Factors of Usability Testing:

1. Testing can be a distressing experience
    

1. pressure to perform, errors inevitable
    
2. feelings of inadequacy
    
3. competition with other subjects
    

3. Golden rule: subjects treated with respect
    

Ethics Before:

1. Do not waste user time
    

- pilot tests to debug experiments and questionnaires
    
- have everything ready before user shows up
    

2. Make users feel comfortable
    

- emphasize the system is being tested not the user
    
- let users know they can stop at any time
    
- acknowledge the software may have problems
    

3. Maintain privacy
    

- test results will remain confidential
    

4. Inform the user:
    

- explain any monitoring being used
    
- answer all user questions (avoid bias)
    
- users to sign informed consent form
    

Ethics During:

5. Do not waste user time
    

- never have user perform unnecessary tasks
    

6. Make users feel comfortable
    

- give early success experience
    
- keep relaxed atmosphere (breaks, food)
    
- hand out test tasks one at a time
    
- never indicate displeasure at userâ€™s performance
    
- avoid disruptions
    
- stop test if it is unpleasant
    

Ethics After:

7. Make users feel comfortable
    

- state the user has helped you find areas of improvement
    

8. Inform the user:
    

- answer specific questions about experiment that could have biased results
    

9. Maintain privacy:
    

- never report results in a way individual users can be identified
    
- only show images/videos with explicit permission (outside research group, consider blurring faces)
    

  

Week 6:

  

Microinteractions:

Chapter 1: Designing Microinteractions

  

Experience Design: bridging big picture features with detail of microinteractions for consistently great experience

Feature: complex, multi-use case, time consuming, cognitively engaging (music player)

Microinteractions: interaction with one function (atoms of interaction), simple, brief, effortless (adjusting volume)

- accomplishing single task
    
- connecting devices together
    
- interacting with single piece of data
    
- controlling ongoing processes
    
- adjusting a setting
    
- viewing or creating a small piece of content
    
- turning feature/functionality on or off
    

Can Be Big:

- whole product (toaster)
    
- set context for features, make or break final product (design of product only as good as smallest part)
    
- they are â€œfeelâ€ of look and feel
    
- tie together features across devices
    
- reduce complexity to most lightweight product/interaction possible
    

History:

- Gypsy word processor with GUI, no modes (previously keys typed or meant commands in different does), invented copy and paste
    
- XEROX PARC scrolling by pixel instead of by line (demoed to Steve Jobs)
    
- Apple switches scroll direction to match touch screen devices
    
- electricity/digital technology has made actions increasingly abstract
    

Structure:

1. Structure: trigger
    

- user initiated or device initiated
    
- start from understanding user needs and frequency
    

Controls: most important part of user-initiated triggers (most frequently used so always present)Â 

2. Rules: result
    
3. Feedback: anything seen/heard/felt to help user understand the rules
    

- place to express personality
    

4. Loops/Modes: meta rules
    

- lasting over time? expire? interruptions?
    

Microinteraction Philosophies:

1. Case-By-Case: consider/implement each microinteraction individually
    

Signature Moment: product differentiating microinteractions

2. Reduced: reduce product to its essence/one microinteraction it does well
    
3. Detail of Product: treat entire product as set of microinteractions
    

  

Summary:

This weekâ€™s reading was about the importance and history of microinteractions, as well as some approaches to implementing them into products. Microinteractions are the smallest functions a product provides, and do only one function each, making them akin to the atoms of a product. Features, by contrast, are the entire system or product the microinteractions are embedded in. Features take effort and intention to use, for example a music player, whereas microinteractions are effortless, like skipping a song or turning up the volume. Although microinteractions are the smallest features of a product, they are what set the context of each feature, and make up most of the minutiae of the userâ€™s experience, meaning they are critically important to the success of a product. Microinteractions are powerful to engage users with unique and positive experiences and create consistency across devices. Each microinteraction is made up of four components. The structure is the triggering event or condition, the rules are the result of that trigger, the feedback is what is indicated to the user to form an understanding of the structure and rules, and the loops and modes of a microinteraction relate to the meta rules of use across time and contexts. Microinteractions are the details that make up a product experience so should not be neglected, and ideally should be designed individually, and in consideration of the system as a whole to use them to their full potential.

  

Question:

You are hired to make a word-processing app for smartphone users. Before moving to production, you plan to identify user goals by interviewing potential users and map out user flows for each feature and functionality. Where in the process should you consider the microinteractions of the application, and how can this be accomplished?

  

Answer:

There is no one way to implement or plan microinteractions, but it is likely best to first interview the potential users to deeply understand their goals and needs from the app. From there, you can start to prioritize what features are essential, and in what contexts would users be using them, and consider microinteractions. If there is one main goal or task users face, for example writing documents accessible across devices, focusing on creating one specific flawless microinteraction may be the best way to go. This makes an elegant product and avoids feature bloat that can confuse and overwhelm users. If, however, users identify multiple goals and tasks they want to accomplish, like editing documents, sharing with others, changing formatting, checking grammar and spelling, listing all potential microinteractions to implement may be an appropriate course of action. This would pair well with user journey maps, as at each action or crossroads, there is typically a microinteraction a user faces or acts upon. After employing this approach of breaking down the final product to its base microinteractions, you would ensure each microinteraction is consistent with the app goals and language of interaction, and actually serves a purpose instead of getting in the userâ€™s way.Â 

  

Lecture Week 6:

1. Design Patterns: formed from years of trial and error
    

â€œNaturalâ€ User Interface: content serves as interface, easily guessable by physical/realistic gestures, leverage skills from life experience (have limitations)

Interactivity Patterns: user action > reaction > perception (understanding of reaction)

1. Anticipation Pattern: anticipate what users need/when they need it
    
2. Autonomy Pattern: leave users in charge of interface, donâ€™t force orders/limits unless necessary
    
3. Hierarchy Pattern: clarifying to user order of functional importance
    
4. Consistency Pattern: interface stays consistent to retain user understanding
    

Design Pattern: how UI is displayed based on conventions and trial and error

2. Microinteractions: the â€œbrushstrokesâ€ of UX, single task (like sentence)
    

1. Trigger: user or system instantiation
    
2. Rules: what happens after trigger is initiated, limits/constraints of interaction
    
3. Feedback: response to initiation (visual, aural, haptic, goal is to give user only necessary information to understand the interaction)
    

  

Week 7:

  

Why We Fail: important to analyze failures because online world is becoming essential

Design-Related Failure:

1. Engineering Failure: physically fails
    
2. Design Failure: physically works but hard/impossible to use
    
3. Experience Failure: physically works and can be used but undesirable
    

  

Death of the Spec: specs not as important as experience now

- qualities of experience are subjective (contextually and culturally dependent, only know from testing success)
    

  

Experiential Threshold: crossed when technology is advanced enough to engage emotions

  

- difference between getting design right (works/nice) and getting right design (solving right problem)
    
- experience goals > tech goals
    
- users and companies overlook flaws if there are enough benefits (in experience)
    
- touchscreen is better for naive users
    

  

Summary:

This weekâ€™s reading was about studying design failure to learn how to avoid common pitfalls that jeopardize a productâ€™s success. It covered the different kinds of design-related failures, engineering failure, when something physically fails, design failure when something physically can work but has poor usability and experience failure, when the product can work and does work but offers an unpleasant experience so is unused. Although engineering and design failure are more popularly discussed, experience failure is the underlying reason why many products fail. Currently, technology has surpassed the â€œexperiential thresholdâ€ where it is advanced enough to engage emotions, and now users expect not only that it works and allows them to complete tasks, but that interaction with it is pleasurable. This was exemplified with the iPhone 4 that sold in record numbers despite a design-related issue of decreased reception when held at a certain angle. This focus on experience over actual capacity is called â€œdeath of the specâ€ and indicates that the experience of usage is the most important variable to users, as they will overlook design flaws if they have good reason to. Another factor dictating the success of a design is if it is actually solving the right problem, as a pleasurable design will be useless if it is inapplicable to the userâ€™s tasks and goals.Â 

  

Question:

You are part of the design team making a new app to allow users to schedule their coffee order in advance so they donâ€™t need to remember to order it online each day. This allows them to save time instead of ordering it each day. The client wants the app to be applicable beyond coffee orders to groceries and other regular purchases, but you arenâ€™t sure if this will aid or confuse users. What can you do to learn what may be applicable to users, and what should you prioritize during creation of the app?

  

Answer:

Conducting user interviews is a good way to learn how potential users would use the app and what their needs actually are. Extra features can be useful, but users are more interested in the experience of a product than all the capacities it has, especially at the start when they can be overwhelming. If users are on their way to work and picking up their regular coffee, it is unlikely they would want groceries too, but if they are on their way home maybe they would. Once a prototype is made, user testing is helpful in deducing if the experience is actually positive, as experience assessment is subjective and difficult to predict without direct feedback. The biggest factor in the success of the app will be the user experience, so this must be considered seriously, as users want to use something that provides a desirable experience and will not stay for features if an app causes difficulty and poor experience.

  

Week 8:

  

Lecture Week 8: Usability Testing 1

1. Usability: extend to which product can be used by specified users to achieve specific goals with effectiveness and satisfaction in specified context of use (without frustration)
    

- frustration and satisfaction are different dimensions
    

2. UX Design: personâ€™s perceptions and responses resulting from use of anticipated use of product, interactive system or service
    
3. Nielsen Usability Components:
    

1. Learnability
    
2. Efficiency
    
3. Memorability
    
4. Error Prevention
    
5. Satisfaction
    
6. (Not Frustrating)
    

5. Usability Testing: assessing how people try to complete tasks with system and if it satisfies goals
    

- learning opportunity, mitigates risks, exposes issues and false assumptions about expected patterns of use (does it suit realistic norms of everyday practice? is it a realistic task? does it help or hinder?)
    

Types:

1. Summative (verification): testing full product to see if meets predetermined standards
    

- based on numbers/stats
    

Limits: often done in artificial test environments, not really proof that

product works, time consuming/difficult to properly conduct

extensive comparative tests, measures learnability (because

first-time user) over usability (general usage)

2. Qualitative: observing user interactions, explanations, descriptions, anecdotes to understand mental model and usability dimensions
    

1. Think-Aloud Method: use prototype and speak aloud what they are thinking, trying to do, why they took certain actions, how they interpret what they did
    

Pro: insight into user thoughts

Con: may alter how users do task, unnatural/awkward, hard to talk while concentrating

2. Constructive Interaction/Co-Discovery Learning: two people work together on task (one on computer) and talk to each other (think aloud without awkwardness), start with semi knowledgeable coach instructing novice on tasks, questions and interactions give insight into 2 user groups
    

Recording Observations:

1. paper/pencil (events, comments, interpretations)
    
2. video recording (record screen with mirror showing face and hand movements)
    

  

Running Usability Study:

1. Define purpose/concerns and usability targets
    

Assessing:

1. Conditions (with 1 year of experience)
    
2. Criteria (20% complete task)
    
3. Performance (within 10 minutes)
    

Usability Targets:

1. effectiveness (ability)
    
2. efficiency (time)
    
3. attitude (satisfaction/frustration)
    

2. Create set of realistic tasks
    

- doable in less than an hour, get at 5 aspects of usabilityÂ 
    
- start with written scenarios describing specific goals
    
- communicate intent not operations/mechanics of task
    
- donâ€™t use works existing in UI elements (no hints)
    
- pre-test questionnaire (gather background information, experience level)
    
- post-test questionnaire (assess thoughts and opinions after relating to 5 aspects of usability)
    

3. Pilot study
    

- test study method with friends/colleagues to figure out right questions/timing
    

4. Find participants
    

- ideally end users or similar
    

5. Conduct Study
    

Study Protocol:

- introduceÂ 
    
- answer pre-test questionnaire
    
- get existing conceptual model
    
- have user complete tasksÂ 
    
- answer post-test questionnaire
    
- conduct short retrospective interview
    
- have complete same tasks in same sequence
    
- watch for inconsistency between participants and app vocabulary, screens participants pause on, type and number of mistakes made
    

6. Observe
    

- let them make mistakes
    
- record questions but do not answer them
    
- donâ€™t be present in the room
    

7. Completion
    

- thank them and give post-test questionnaire
    
- token of appreciation is expected
    
- emphasize the system was being tested not them
    

8. Analysis:
    

- identify common results
    

1. Quantitative: number data in accordance with usability targets
    
2. Qualitative: anecdotes from users
    

When People Get Stuck:

1. problems getting started: yes help them
    
2. problems during usage: help as little as possible, skip task if cannot do it
    

Report on:

- list of major issues
    
- prioritized recommendations
    
- task success rate table
    
- user quotes
    
- post-test questionnaire results
    

  

Playtesting Reading:

Types of Testing:

1. Focus Group: potential users interviewed about likes and dislikes to structure priorities
    
2. QA Testing: quality assurance looking for bugs/issues
    
3. Usability Testing: determining if system is easy to use/intuitive
    
4. Playtesting: getting people to play game to see if it elicits desired reaction
    

Why:Â 

- prototypes to ask specific question/get specific answer
    
- should be specific purpose to testing
    

Who:

1. Developers: convenient but biased
    
2. Friends: convenient, more comfortable but biased
    
3. Expert Gamers: detailed feedback/comparison but more skilled than average player
    
4. Tissue Testers (never before seen game): will notice what you are used to but only show first-time appeal
    

Where:

1. Studio (workplace): convenient but intimidating
    
2. Lab (designed for playtesting): all set up but expensive
    
3. Public Venue: many testers but may not be target demographic, may be distracted
    
4. Testerâ€™s Home: game in natural habitat, less convenient
    
5. Online: more testers but less depth of knowledge (include constant text entry to send feedback to mitigate this)
    

What:

1. Things you know youâ€™re looking for (answer to specific question)
    
2. Things you donâ€™t know youâ€™re looking for (be open to additional insight)
    

How:

- should you be there?
    
- what to tell them up front (framing influences gameplay so be careful)
    
- where do you look (at face to gauge emotions)
    
- what other data to collect? (average score, features used, tries)
    
- will I disturb players midgame? (only if extremely important, otherwise disrupts natural gameplay, use thinking out load approach)
    
- what data to collect after? (follow up)
    

- Surveys: not too many questions, rate 1-5 not 1-10, use pictures to aid recall, right after
    
- Interviews: use script, make private, ask more than need, use recognition cues
    

  

Summary

This weekâ€™s reading was about the importance of playtesting games. Playtesting differs from other kinds of testing, because it intends to assess if the product elicits the desired response. Other kinds of testing focus on user attitudes (focus groups), usability and technical issues (quality assurance testing). Although other kinds are also important, playtesting is critical for understanding the audience response. Playtesting, like prototyping, should aim to answer a specific question. It is most valuable when it is specific, instead of broad, as this gives direction to the tests and findings. Playtests can be conducted in public venues where there are many people, in workplaces or labs or at the usersâ€™ house (in-person or online). The kind of tester also depends on the questions being asked, but generally there are four types: the developers (employees), family and friends, experts and beginners. These groups will all provide different kinds of feedback, so it is best to test with more than one. Testing will help answer specific questions, but also offer unexpected insights into issues that should be addressed. During gameplay, it is best not to disrupt the testers to simulate real life gameplay, and get additional information later through interviews or surveys conducted immediately following gameplay.

  

Question

You are on the team developing a mobile app that connects in-person shopping experiences to online wishlists and favouriting. Before and during production, how can you get insights into the user needs and priorities to ensure the app is a success?

  

Answer

A good way to gather initial data would be to talk to people visiting malls or shopping outlets with surveys or interviews, to understand their shopping habits and use of online and offline shopping services. This is akin to a focus group, but in a more natural setting, providing you a wide range of potential users. Once this data is collected, insights about the end usersâ€™ priorities can be drawn to form the structure and features of the app. With medium fidelity prototypes, the app can be â€˜play testedâ€™ by allowing users to try it out while being observed. This will give insight into not only the usability and functionality, but the reactions the app elicits. If the app goal is convenience and time saving, but everyone using it is becoming frustrated by the confusing and slow interface, there is a mismatch that needs to be resolved. The experience is what users take away from interactions, so ensuring the experience provided matches the intention is critical for a successful product. After usage, interviews and surveys could be used to gauge the specific issues and pain points for users, as well as the areas they appreciated and find valuable.

  

Reading Week 9: Testing During Covid19

  

Issues During Covid:

- closed research labs, no in-person user studies (requiring use of head-mounted displays)
    
- hardware and ethical (privacy) concerns
    

1. Short-Term Solution: use lab personnel and infrastructure
    

- be participants for each othersâ€™ experiments
    
- may have too much knowledge to give representative data that is generalizable, expectations change behaviour
    

2. Medium-Term Solution: recruit external users who have hardware
    

- 6 million people have a VR headset, recruit those that have the hardware
    
- no easy tools for running online VR experiments
    
- crowdsourcing website to find participants online
    

3. Long-Term Solution: generate pools of users through funded hardware distribution
    

- provide equipment to people to participate in multiple experiments
    
- removes the need to bring participants into lab
    
- registered through citizen science crowdsourcing site
    
- get compensation for participation
    
- can be unideal because very experienced with vr and experiments
    

4. Ethical Considerations:
    

- pooling students to run each otherâ€™s experiments (no inducement)
    
- desktop sharing (only share assessed system screen)
    
- running studies on social vr platforms (may require personal information)
    
- open platformsÂ 
    
- videoconference screen share
    

5. Health Considerations:
    

- domestic environments are not wide open like lab, participants may not have same range of motion
    
- hardware quarantine between users (72 hours)
    

6. Validity of Results
    

- uniform hardware is difficult remotely, may need to open requirements to get enough participants
    

7. Remote Experiment Design Guidelines
    

- record or observe through videoconferencing software
    
- remove as many accessibility barriers as possible with multimodal feedback systems (UI, voice and text)
    
- consider cultural/geographical impact on results
    
- required workload minimized with automating setup as much as possible (may not be there to help through steps)
    
- all surveys within vr, typing not as efficient so use other UI widgets
    
- collect data about device, frame rate, connection while experiment is run
    
- solicit feedback from other labs
    
- ask questions in interview after to gauge quality of whole experience
    

  

Summary

This weekâ€™s reading was about assessing virtual reality technological systems during the pandemic when in-person testing is impossible due to safety concerns. Because testing is still essential for these systems, three kinds of solutions are offered. The first is a short-term solution of using colleagues to test each otherâ€™s experiments. This provides the participants needed, but may not produce generalizable results, as these participants will be much more experienced with HMDs and VR systems than the general public. Another solution is testing on people who own some sort of VR technology or HMD. It is estimated that 6 million people have HMDs, so recruiting some of these people online could be a viable way of testing VR technology. The limitations are again that people who own VR systems may be more experienced with it than general users, but they may also represent the populations that will be most likely to use new VR technology, so could yield better results. A last, long-term, solution would be to provide HMDs and VR technology to people to participate in many experiments, getting a broader participant pool than just those that work in labs or own HMDs already. This solution comes with the issues of sanitizing and distributing headsets, and also movement limitations in home environments as opposed to labs, but could provide more diverse data.Â 

  

Question

You are developing a VR application and need to test it remotely. What steps can you take to ensure the testing is ethical and safe to your participants, and that results are generalizable?

  

Answer

To test the application, you could use colleagues first to work out initial issues, as this requires less preparation and expense. After target users are identified, recruiting users with HMDs or lending HMDs to users are viable options for remote testing. When observing results you can use videoconferencing, but should only be seeing (and possibly recording) the screen of the system being tested to avoid breaching the participantâ€™s privacy. Also the limitations of movement should be taken into account to ensure participants do not injure themselves or damage their surroundings during the experiment. A last consideration is the cultural differences users will bring, as online recruiting offers a broader participant pool that may come from many different countries. Systems should be accommodated to different languages and conventions to ensure results are valid and reflect the variables being tested.

  
  

Reading Week 10

  

Natural User Interfaces: exploit skills acquired from life experiences to reduce cognitive load and distraction

- only natural in certain context to user of certain skill level
    

- use touch, gesture, voice
    

- easy to use, adapt to human needs, interaction consistent with natural behaviour
    
- feels easy, fun, natural
    
- some are analogous to real world, some require learning
    

Guidelines:

1. Instant Expertise: reusing existing skills (common to humans or from domain expertise)
    
2. Progressive Learning: clear path from basic to advanced in increments (experts not forced to do this)
    
3. Direct Interaction: direct correlation between action and NUI responseÂ 
    

1. Directness: touching
    
2. High-Frequency Interaction: continuous
    
3. Contextual Interaction: show only information relevant to current interaction
    

5. Cognitive Load (Reduction)
    

  

Future UI Without Buttons:

- voice control
    
- touching entire screen (but no button indicator)
    
- gesture recognition
    

Pro:

- save time
    
- prevent errors
    
- compensate for accidental actions
    

  

Using Voice Interaction in VR:

- VR at best when multimodal (gaze, gesture and voice)
    

Goal:

- say and get clear feedback that system heard and is reacting
    

Pro:

- reduces time
    

- minimizes effort
    
- reduces cognitive load
    
- socially acceptable (if within contextual norms)
    
- routine
    

Con:

- bad at accents/women
    
- imprecise scale control (how much louder)
    
- voice can be imperfect
    
- may not be publicly acceptable
    

Tips:

- concise commands
    
- simple vocabulary
    
- non-destructive commands
    
- no similar sounding commands
    
- unregister when not in use
    
- test with different accents
    
- maintain consistency
    
- avoid using system commands
    

  

Summary

This weekâ€™s readings were about developments shaping future user interface design like increasing gesture control, eliminating buttons and using voice commands. Many natural actions in real life require gestures and movement, so mapping these already learned actions onto user interfaces could make them more intuitive and natural to use. This is called Natural User Interface and it relies on pre-existing knowledge to be used, making it feel natural, easy and fun. NUIs decrease the cognitive load of the user, as the actions are already understood so they do not require conscious effort. NUIs should strive to be instantly usable with progressive incremental steps leading to expertise. They also provide direct interaction where usersâ€™ actions are immediately followed by system feedback so users can map their actions to the responses to increase understanding. An extension of the NUI concept is removing buttons from UI, and instead using gestures performed across the entire screen to control and navigate on devices. Multimodal interactions are ideal for the most engagement, so incorporating voice commands is also an area of interest for future UI development. Voice commands should be simple, short and easily understandable to ensure they actually serve the users and provide the intended benefits of saving time and energy.

  

Question

You are developing an app that requires voice control to complete many of its functions. What are important considerations to keep in mind when developing this, and what can you implement to reduce errors and increase satisfaction?

  

Answer

Although voice control has benefits of saving time and effort, it can also slow users down. Voice recognition generally is less accurate when users have strong accents or unique voices, so adequate testing with a variety of users is essential to ensure the system works for a wide range of potential users. Other considerations are having the commands taught to users incrementally to avoid overwhelming them with a list of commands to memorize. Having commands shown visually could aid with this. Also, having visual fallbacks where the user can complete the same action though touch or gesture would ensure that users arenâ€™t forced to use voice control in contexts that donâ€™t suit it, like in public spaces. Ensuring that commands are unique and do not sound similar and short could also aid both user retention and system recognition.

  

Week 8: Usability Testing 2

  

Surveys: automated interviews generating a wide range of opinions from large samples

Pro: cheap, large sample

Con: time consuming to prepare, potentially low response rate or low quality response

- not a substitute for usability testing
    
- used in usability study (pre-test questionnaire to identify experience and potential biases before use and post-test questionnaire to understand experience with 5 aspects of usability and concern areas)
    

Rules:

- up front know purpose, audience and analysis methods
    
- donâ€™t ask questions you donâ€™t need the answer to
    
- ask most important questions â…“ through (start with easy)
    
- reliability checks spaced apart and phrased differently
    
- save personal questions to end (so if leave still have initial responses)
    
- test wording, timing, validity, analysis
    

Administering:

1. In-Person: highest response rate but intrusive
    
2. At Home: lower response/return rate
    
3. Email: less time constraints, more relaxed
    
4. Web-Based: can have scripts to ensure completeness, convenient
    

Timing and Question Amount: (these are absolute maximum)

1. Phone: max 20 questions
    
2. Mail: max 60 questions
    
3. Group: max 100 questions (peer pressure keeps people going longer)
    
4. Interview: max 80 questions
    

Question Styles:

1. Open-Ended: asks for opinions
    

- hard to analyze (subjective)
    
- provides detailsÂ 
    

2. Closed: supply choice of answers
    

- easier to analyze
    
- loses details/why of response
    

3. Funnel: start with open-ended, move to closed
    

- good for sensitive topics
    

4. Reverse-Funnel: start with closed, move to open questions
    

- good for non-threatening topics
    

5. Paired Comparison: select which of two options they like better
    

- can have incongruent responses (do not use pairs when more than 2)
    

6. Ranked Order: rank 3-10 items to understand preferences and priorities
    

- magnitude between unknown, no why for ranking order
    

7. Likert Scale/Scalar: measures opinion/attitude ranking in equally spaced scale (1-5 or 1-7) with clear neutral response
    

- depending on culture extremes responses will be different (may not do extremes so use 1-7 and use 2-5 as actual scale)
    
- can also be used to explore bipolar attitudes about items
    

8. Multiple Choice: offer explicit responses, responses not included receive an â€œotherâ€ response
    
9. And More (constant sum, graphic scales, thurstone scales, stapel scale)
    

  

Thematic Analysis: extracting themes from data

Qualitative Data > Coding > Codes > Iterative Comparison > Themes

Coding: open inquiry into data to make questions that can be answered with codes (questions can be explicitly asked before or new from seeing data)

1. Transcribe data
    
2. List questions to answer with codes
    
3. code data
    

Memos: heading/date and insight from coding/data

4. Results: list of codes/frequency/sense of frequency of code
    

- go through codes, rate severity of problem (major/minor)
    

5. Themes: aggregate codes into themesÂ 
    

- can naturally arise from data (bottom-up) or come from reason doing study (top-down)
    

Affinity Diagram: clustering method to categorize/show relationships amongst

data (post it on whiteboard in theme clusters, refine themes)

  

Communicating Peopleâ€™s Behaviours:

- convey results with scenarios/stories about people/activities/goals (greater empathy, more convincing, more memorable)
    
- best stories based on codes/themes, ties data to understanding
    

Common User Models:

Empathy Maps: visualize customer needs/data into clear, simple chart of what they think/feel/see/do/want

- classic UI methods do not talk enough about emotions, especially frustration
    
- journey map lacks detail for edge cases (when itâ€™s frustrating/things donâ€™t work)
    

  

Lecture Week 9: Analyzing Results and Iterative Design:

- insight is better than numbers to improve a design, numbers are better to track improvement
    

Qualitative Measures: 3-5 users means more bang per buck

Quantitative Measures: at least 20 people for usability metrics

Usability Metrics:

1. success rate
    

- easy to collect, telling
    
- collect data of when failures happen and to who
    

2. time a task requires
    
3. error rate
    
4. userâ€™s subjective satisfaction
    
5. create more/custom
    

  

Measuring Success:

1. when subsequent can add all together and average improvement together
    
2. when not subsequent get average improvement for each task
    
3. ISO Standards:
    

1. effectiveness: # tasks completed/#tasks tried
    
2. efficiency: # of errors (description, severity, rating, category, priority)
    
3. satisfaction: how difficult was each task (regardless of success)
    

5. SUS: System Usability Scale: best for task level, well validated
    

- ideal for use with small samples, simple to administer, accurate (balanced)
    

  

Quantitative Data Analysis:

Descriptive Statistics:

- frequency of errors
    
- mean and standard deviation
    
- mean and range
    

- always question data results, why are there certain findings/results/groups within data

Mean v. Geometric Mean:

- arithmetic mean can hide reduction in improvement, geometric more true balance
    

  

Iterative Design: after testing go back, redesign and try again

Plan > Research > Design > Adapt > Measure > Plan (repeat)

- ui/ux are iterative processes, easier to design prototype and refine than develop and change, the more users the more issues
    

  

Lecture Week 10: Errors, Attention, Copywriting

  

Errors: job of ux is minimizing frequency and impact of errors

- cannot eradicate but can avoid/facilitate recovery
    
- hallmark of good design is helping people recover from errors as painlessly as possible
    

1. Slip: you know what to do but you slip up and execute task wrong
    
2. Mistake: donâ€™t know what to do but you think you do
    
3. Failure: you have no idea what to do (either know there is process but donâ€™t know it or donâ€™t know process)
    

  

Orders of Ignorance:

0. lack of ignorance

1. donâ€™t know something but can identify that donâ€™t know

2. donâ€™t know you donâ€™t know

3. donâ€™t know how to get to point of understanding what you donâ€™t know (no process)

4. donâ€™t know about orders of ignorance (meta ignorance)

  

Error Types:

1. Capture Error: continue frequently done activity instead of intended one (habitual response, especially with similar start sequence)
    
2. Description Error: intended action has much in common with others (usually when distracted or in close proximity)
    
3. Data Driven: triggered by arrival of sensory information which intrudes into normal action
    
4. Associative Activation: internal thoughts and associations trigger actions
    
5. Loss of Activation: forgetting goal in middle of action sequence
    
6. Mode Errors: do action in one mode thinking in another mode
    

  

3 Phases of Interaction:

1. Read-Scan Phase
    

Perceptual Errors: insufficient/poor perceptual cues, lack of feedback, visual similarity, poorly expresses states, failure to captivate user attention (show state clearly!!)

2. Thinking Phase
    

Cognitive Errors (Mistakes): from straining memory and problem solving capabilities, strain recall, lack of good mnemonic aids, inconsistency, lack of context/status, mental translations/calculations, inconsistent language

3. Response Phase
    

Motor Errors (Slips): taxing eye-hand coordination and motor skills, awkward motor movements, similar sequences

  

Preventing Errors: recognize where users are making errors from user testing

Attention: focus and guide to reduce errors, selective (one input per channel at a time)

Gestalt Principles: making things stand out at low level processing, universal

  

Recovery from Errors:

- allow undo/recover checkpoints before destructive actions (confirmation dialog, trashcan stage)
    
- autosave/data recovery systems
    
- anticipate correct response
    

  

Error Messages:

- polite, correct tone for audience/situation, correct grammar, understandable, tell user why and give way to fix (you want to decrease stress)
    

1. Wording: easy to read, meaningful, guide user to nature of errors
    
2. Tone: conversational, helpful, nonaggressive
    

  

Copywriting: the words matter

- what products say to people who use them matters
    
- helps decrease errors, reduce training time, improve impressions
    

1. Greeting: onboarding, state purpose of site and most common steps in clear English, setting tone for future communication, keep user orientation
    
2. Navigation: what do buttons do? clear, descriptive, unambiguous descriptions
    
3. Suggesting Actions: call to action that encourages user to further use interfaces
    
4. Providing Service: help/error message, guidance
    

  

Priority:

1. Always increase clarity, the words you use matter
    
2. Be specific, state exactly what you mean consistently
    
3. Avoid Jargon: speak the userâ€™s language so they donâ€™t feel stupid
    
4. Be Concise: use only as many words as you need (balance concise with understandable)
    
5. Personality is good but not at expense of clarity (avoid outdated slang)
    
6. Donâ€™t be lazy! Take time to check copy, no typos, clear, appropriate, be professional
    

  

Lecture Week 11: Dark Patterns

  

Ethics: focused UI is usually limited to academia, makes practitioner access to conversations difficult

  

Brignullâ€™s Typology of Dark Patterns:

  

5 Dark Strategies:

1. Begging: minor redirection of expected function that persists over multiple interactions
    
2. Obstruction: impede a task flow making interaction more difficult than it needs to be to attempt to dissuade action
    
3. Sneaking: hiding/disguising/divulging relevant information**
